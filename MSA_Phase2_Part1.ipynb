{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92bb064-c788-4ca4-9401-ab26e4925157",
   "metadata": {},
   "source": [
    "## MSA 2024 Phase 2 - Part 1 Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1b763-2482-489b-bc94-56b936f48f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ff921-ecc8-406e-ade9-39bbb1d04cce",
   "metadata": {},
   "source": [
    "### 1. Find all variables and understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9c441-7cd0-44d9-8633-30680cd1c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose W Store Sales as the dataset and merged the three tables\n",
    "url_features=\"https://raw.githubusercontent.com/NZMSA/2024-Phase-2/main/data-science/0.%20Resources/datasets/W%20store%20sales/features.csv\"\n",
    "df_features=pd.read_csv(url_features)\n",
    "df_features.info()\n",
    "\n",
    "url_sales=\"https://raw.githubusercontent.com/NZMSA/2024-Phase-2/main/data-science/0.%20Resources/datasets/W%20store%20sales/sales.csv\"\n",
    "df_sales=pd.read_csv(url_sales)\n",
    "df_sales.info()\n",
    "\n",
    "url_stores=\"https://raw.githubusercontent.com/NZMSA/2024-Phase-2/main/data-science/0.%20Resources/datasets/W%20store%20sales/stores.csv\"\n",
    "df_stores=pd.read_csv(url_stores)\n",
    "df_stores.info()\n",
    "\n",
    "# Merging the three tables by the unique keys\n",
    "merged_data=pd.merge(df_sales, df_features, on=['Store','Date','IsHoliday'],how='left')\n",
    "merged_data=pd.merge(merged_data, df_stores, on='Store', how='left')\n",
    "\n",
    "merged_data=merged_data.sort_values(by=['Store','Dept','Date'])\n",
    "                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece2ca9-79b7-4b03-b60d-44d6dcc33de0",
   "metadata": {},
   "source": [
    "### 2. Setting the labels and the distribution of values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3b6e4-5c9f-4036-a130-4e5bcf7cd242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the following 12 weekly sales as labels\n",
    "for i in range(1,13):\n",
    " merged_data[f'Weekly_Sales_{i+1}w']=merged_data.groupby(['Store','Dept'])['Weekly_Sales'].shift(-i)\n",
    "print(\"The number of rows before data processing:\", merged_data.shape[0])\n",
    "merged_data=merged_data.dropna(subset=['Weekly_Sales_13w'])\n",
    "print(\"The number of rows after data processing:\", merged_data.shape[0])\n",
    "\n",
    "# the distribution of values in columns\n",
    "merged_data.info()\n",
    "merged_selected_types=merged_data.select_dtypes(include=['float64', 'int64'])\n",
    "mean=merged_selected_types.mean()\n",
    "variance=merged_selected_types.var()\n",
    "std=merged_selected_types.std()\n",
    "quantiles=merged_selected_types.quantile([0,0.05,0.25,0.5,0.75,0.90,0.95,0.96,0.97,0.98,0.99,1])\n",
    "print(f\"\\n Mean:\\n{ mean} \\n Variance :\\n{variance} \\n Standard deviation:\\n{std} \\n Quantiles:\\n{quantiles}\\n\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(merged_selected_types.isnull(),cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Missing Values Heatmap in Merged Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef9cb66-8295-4ca2-bdc2-268774481c60",
   "metadata": {},
   "source": [
    "### 3. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac1075-ea74-4d5d-a8b5-31a23911f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "# Consider the solution to process the missing values in columns\n",
    "for i in range(1, 6):\n",
    "    print(f\"the number of 0 in MarkDown{i} is: {(merged_data[f'MarkDown{i}'] == 0).sum()}\")\n",
    "# Considering that the proportion of missing values in columns Markdown1-5 exceeds 70%, and there are valid values of 0, \n",
    "# in order to avoid unexpected impacts on the model results, these columns will not be considered as input variables (X variables) \n",
    "# in the subsequent modeling process.\n",
    "\n",
    "#Transfering the bool variable into numeric \n",
    "merged_data['IsHoliday']=merged_data['IsHoliday'].astype(int)\n",
    "# Convert \"Type\" to numeric type, create a mapping dictionary, and use the map method to convert the type to integer\n",
    "type_mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "merged_data['Type'] = merged_data['Type'].map(type_mapping)\n",
    "# to avoid the influence of outliers in y lables, we drop the values which are lager than 90% quantile and smaller than 10%\n",
    "data_frames = {}  # Used to store processed dataframes\n",
    "for i in range(2,14):\n",
    "    quantile_10 = merged_data[f'Weekly_Sales_{i}w'].quantile(0.10)\n",
    "    quantile_90 = merged_data[f'Weekly_Sales_{i}w'].quantile(0.90)\n",
    "    filtered_data = merged_data[(merged_data[f'Weekly_Sales_{i}w'] >= quantile_10) & (merged_data[f'Weekly_Sales_{i}w'] <= quantile_90)]\n",
    "    # Delete sales data for other weeks, ensuring that there is only one y label at a time\n",
    "    cols_to_keep = [col for col in filtered_data.columns if col == f'Weekly_Sales_{i}w' or 'Weekly_Sales_' not in col]\n",
    "    filtered_data = filtered_data[cols_to_keep]\n",
    "    data_frames[f'Weekly_Sales_{i}w'] = filtered_data\n",
    "\n",
    "for week, df in data_frames.items():\n",
    "    print(f\"Number of rows retained for {week}:\\n {df.info()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ba54d-af7e-4b0b-b28b-5956401fc36d",
   "metadata": {},
   "source": [
    "### 4. Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad01de-c7cf-4670-ad3d-d6508a469a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the histograms and box graphics to show the distribution of values and outliers intuitively and directly\n",
    "# Set the style of graphics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Iterate the DataFrame\n",
    "for week, df in data_frames.items(): \n",
    "    # Select columns of type float64 and int64\n",
    "    numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    for column in numerical_df.columns:  \n",
    "        # Draw histograms\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(numerical_df[column], bins=10, kde=True)\n",
    "        plt.title(f'Histogram of {column} with {week}')\n",
    "        plt.xlabel(f'{column}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "        plt.close()  \n",
    "\n",
    "        # Draw box diagrams\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x=numerical_df[column])\n",
    "        plt.title(f'Box Plot of {column} in Data with {week}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Value')  \n",
    "        plt.show()\n",
    "        plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb7601-5b87-4f38-8b05-b0a67e2487cd",
   "metadata": {},
   "source": [
    "### 5. Identify correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b47edc-c068-4657-8f85-e2835767b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation coefficient check\n",
    "for week, df in data_frames.items():\n",
    "    numerical_df = df.select_dtypes(include=['float64', 'int64']) \n",
    "    # Calculate the correlation matrix\n",
    "    correlation = numerical_df.corr(method=\"spearman\")  \n",
    "    print(f\"Spearman Rank Correlation:\\n {correlation}\")\n",
    "\n",
    "    # Create a heatmap with seaborn \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title(f'Feature Correlation Matrix Heatmap with {week}')\n",
    "    plt.savefig('Feature Correlation Matrix Heatmap.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5653c2d3-1e31-4f84-9b04-b9ce2812e1e6",
   "metadata": {},
   "source": [
    "### 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20db9de-c766-4b9e-8bef-fb4c2c01375f",
   "metadata": {},
   "source": [
    "Data Selection and Preparation:\n",
    "I selected the \"w\" store dataset, merging features, stores, and sales tables, with the goal of predicting sales for the next 12 weeks.\n",
    "\n",
    "Data Analysis:\n",
    "The dataset contains 382,955 rows and 27 columns. Key findings include missing values in MarkDown1-5 exceeding 70%, and \"Store\" and \"Dept\" being categorical despite being numeric.\"Type\" and \"IsHoliday\" need conversion to numeric formats. Significant variability was noted in several columns.\n",
    "\n",
    "Data Cleaning:\n",
    "Data cleaning involved converting data types, handling missing values, and processing outliers. Separate datasets were stored for different target variables.\n",
    "\n",
    "Visualization:\n",
    "Heatmaps, histograms, and box plots helped visualize missing values and data distribution, enhancing dataset understanding.\n",
    "\n",
    "Correlation Analysis:\n",
    "Strong correlations were found between weekly sales and the target, as well as between other variables like CPI, unemployment, and Markdown values. This informed potential reductions in model inputs.\n",
    "\n",
    "Conclusion:\n",
    "The initial data exploration and analysis provide a strong foundation for subsequent modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
